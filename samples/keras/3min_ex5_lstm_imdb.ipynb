{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 문장을 판별하는 LSTM 구현\n",
    "\n",
    "- IMDB 영화 추천 데이터를 이용하여 영화평을 분석해 영화 평점 정보 예측\n",
    "- IMDB는 25,000건의 영화평과 이진화된 영화 평점 정보(추천=1, 미추천=0)를 담고 있다\n",
    "- 평점 정보는 별점(star points)이 많은 경우는 긍정, 그렇지 않은 경우는 부정으로 나눠짐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/Users/leesu/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# 라이브러리 임포트\n",
    "from __future__ import print_function\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras import layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋에 들어 있는 문장들은 길이가 다르므로 pad_sequences() 함수를 사용해 동일하게 만듬. maxlen 보다 작으면 부족한 부분은 0으로 채우고 길면 잘라낸다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 데이터 준비\n",
    "class Data:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "        x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "        x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
    "        self.x_train, self.y_train = x_train, y_train\n",
    "        self.x_test, self.y_test = x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "layers 는 인공 신경망의 계층을 만드는 서브패키지이다.\n",
    "- Dense : 완전 연결 계층을 만드는 클래스\n",
    "- Embedding : 단어를 의미 벡터로 바꾸는 계층에 대한 클래스\n",
    "- LSTM : LSTM 게층을 만드는 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 모델링\n",
    "class RNN_LSTM(models.Model):\n",
    "    def __init__(self, max_features, maxlen):\n",
    "        x = layers.Input((maxlen,))  # 입력 각 샘플은 80개의 원소로 된 1차원 배열 \n",
    "        h = layers.Embedding(max_features, 128)(x) # 각 단어가 128의 길이를 가지는 벡트로 바뀜 80x128\n",
    "        h = layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2)(h) # 노드 128개로 구성된 LSTM 계층\n",
    "        y = layers.Dense(1, activation='sigmoid')(h)\n",
    "        super().__init__(x, y)\n",
    "        \n",
    "        self.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 학습 및 성능 평가\n",
    "class Machine:\n",
    "    def __init__(self, max_features=20000, maxlen=80):\n",
    "        self.data = Data(max_features, maxlen)\n",
    "        self.model = RNN_LSTM(max_features, maxlen)\n",
    "        \n",
    "    def run(self, epochs=3, batch_size=32):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        print(\"trainig stage\")\n",
    "        print(\"==\"*10)\n",
    "        model.fit(data.x_train, data.y_train, batch_size=batch_size, \n",
    "                  epochs=epochs, validation_data=(data.x_test, data.y_test))\n",
    "        \n",
    "        score, acc = model.evaluate(data.x_test, data.y_test, batch_size=batch_size)\n",
    "        print(\"Test performance: accuracy={0}, loss={1}\".format(acc, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 16s 1us/step\n",
      "trainig stage\n",
      "====================\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 107s 4ms/step - loss: 0.4616 - acc: 0.7817 - val_loss: 0.4236 - val_acc: 0.8117\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 108s 4ms/step - loss: 0.2996 - acc: 0.8793 - val_loss: 0.3950 - val_acc: 0.8326\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 104s 4ms/step - loss: 0.2158 - acc: 0.9155 - val_loss: 0.4149 - val_acc: 0.8238\n",
      "25000/25000 [==============================] - 18s 724us/step\n",
      "Test performance: accuracy=0.82384, loss=0.4148980760264397\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    m = Machine()\n",
    "    m.run()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
